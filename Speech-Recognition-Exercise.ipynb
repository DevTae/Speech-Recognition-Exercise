{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f35370c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 강의 url : https://youtube.com/playlist?list=PL9mhQYIlKEhdrYpsGk8X4qj3tQUuaDhrl\n",
    "# 참조 논문 : Deep Speech to, Listen attend and spell\n",
    "# 딥러닝 기초 리뷰 : FC Layer, CNN, RNN, LSTM, Attention\n",
    "# Audio Classfication & Tagging : 데이터 파이프라인의 이해\n",
    "# CTC : 논문의 이해, CTC Loss 쓰는 법, Deep Speech2 구현\n",
    "# LAS : Extra 모델 아키텍쳐 이해"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43954060",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Spectrogram 을 input 으로 받고, invariant convolution 을 거친 다음에, RNN (Recurrent Neural Network) 을 거치고, Fully Connected 를 거친다.\n",
    "# 마지막으로 나온 CTC(Connectionist Temporal Classification) 를 Decode 하여 결과값을 얻어냄.\n",
    "# IO Module, Network Architecture, Loss 함수만 잘 설정하면 좋은 모델 만들 수 있음."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b56c83b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Connectivity Patterns + Nonlinearity modules\n",
    "\n",
    "# Connectivity Patterns\n",
    "# - Fully-Connected (FC Layer)\n",
    "# - Convolutional\n",
    "# - Dilated\n",
    "# - Recurrent\n",
    "# - Skip / Residual\n",
    "# - Random\n",
    "\n",
    "# Nonlinearity modules\n",
    "# - ReLU\n",
    "# - Sigmoid\n",
    "# - Tanh\n",
    "# - GRU\n",
    "# - LSTM\n",
    "\n",
    "# Loss\n",
    "# - Cross Entropy\n",
    "# - Adversarial\n",
    "# - Variational\n",
    "# - Maximum Likelihood\n",
    "# - L1 and L2\n",
    "\n",
    "# Optimizer\n",
    "# - SGD\n",
    "# - Momentum\n",
    "# - RMSProp\n",
    "# - Adagrad\n",
    "# - Adam\n",
    "# - Second Order\n",
    "\n",
    "# Hyper Parameters\n",
    "# - Learning rate\n",
    "# - Weight decay\n",
    "# - Layer size\n",
    "# - Batch size\n",
    "# - Dropout rate\n",
    "# - Weight initialization\n",
    "# - Data augmentation\n",
    "# - Gradient clipping\n",
    "# - Momentum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4662f1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fully-Connected (FC Layer) 는 Multi-Layer Perceptron 에 Non-Linearity module 만 뺀 것\n",
    "# x 에 대해 모든 입력값을 가중치 W 입력을 통해 z1, activation 함수를 통해 h, 또 다른 activation 함수로 z2 (y)\n",
    "# h 를 만드는 Non-Linearity Function 으로는 Sigmoid, Tanh, ReLU, Leaky ReLU 가 있다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d11873d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convolution Layer 는 입력을 필터로 사용하여 Convolution 연산 진행\n",
    "# 하이퍼 파라미터에는 필터 크기 F 및 보폭 S 포함. 결과 출력 O 를 feature map, activation map 이라고 부름\n",
    "# Pooling Layer 는 다운 샘플링 작업으로, 일반적으로 Convolution Layer 이후 적용, spatial invariance (공간에 영향 없는) 를 수행.\n",
    "# 특히, Max pool 과 Average Pool 는 각각 최대 값과 평균값을 취하는 특수 종류의 풀링\n",
    "# Pooling 된 데이터를 Fully Connected 로 연결시킬 수 있음"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ca7a777",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1-D CNN in Spectrogram\n",
    "# Convolution filter 의 크기가 frequency 영역대는 고정되어 있으며, Time 에 따라 진행\n",
    "\n",
    "# 2-D CNN in Spectrogram\n",
    "# Convolution filter 의 크기가 frequency과 Time에 따라서 진행됩니다.\n",
    "\n",
    "# Sample CNN\n",
    "# 바로 input 데이터를 waveform 그 자체로 사용할 수 있다.\n",
    "# CNN 이 \"phase-invariant\" representation 을 반영"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b4574b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# RNN 은 Hidden State 를 유지하면서 이전 출력을 입력으로 사용할 수 있는 신경망임.\n",
    "# a^<T> = tanh(WaxX^<t> + WaaA^<t-1> + ba)\n",
    "# y^<T> = softmax(WyaA^<t> + by)\n",
    "\n",
    "# LSTM\n",
    "# GRU (Gated Recurrent Unit) 및 LSTM (Long Short-Term Memory Unit)은 기존 RNN에서 vanishing gradient 를 처리하며 LSTM은 GRU의 일반화된 모델임.\n",
    "# Forget 게이트 등 여러 게이트를 바탕으로 옛 데이터를 기억하도록 함 (RNN 개선)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07230573",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Attention\n",
    "# Encoding 된 정보와 Decoding 된 정보의 Hidden State 간의 Alignment 를 맞추는 것\n",
    "# Hidden State 를 맞추다보면 어떤 스텝에서 어떤 Utterance 를 나타내는지 알 수 있음.\n",
    "# 어떤 시점에 대한 인식과 번역에 쓰임.\n",
    "\n",
    "# RNN계열 encoding 방식에서는 계속 마지막 hidden state까지 학습을 하면서 연산을 해야 했다.\n",
    "# 이러한 문제를 해결하기 위해 input source 와 hidden state 의 관계를 학습시키는 추가적인 Network 를 만든 Attention 이 나옴.\n",
    "# 이 attention 은 output 에 의하여 weight 를 학습하게 된다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e19a36f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
